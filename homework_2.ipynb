{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import re\n",
    "import urllib.request\n",
    "import os\n",
    "import random\n",
    "\n",
    "class ImdbMovieReviews:\n",
    "    DEFAULT_URL = \\\n",
    "        'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "    TOKEN_REGEX = re.compile(r'[A-Za-z]+|[!?.:,()]')\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._cache_dir = './imdb'\n",
    "        self._url = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "        \n",
    "        if not os.path.isfile(self._cache_dir):\n",
    "            urllib.request.urlretrieve(self._url, self._cache_dir)\n",
    "        self.filepath = self._cache_dir\n",
    "\n",
    "    def __iter__(self):\n",
    "        with tarfile.open(self.filepath) as archive:\n",
    "            items = archive.getnames()\n",
    "            for filename in archive.getnames():\n",
    "                if filename.startswith('aclImdb/train/pos/'):\n",
    "                    yield self._read(archive, filename), True\n",
    "                elif filename.startswith('aclImdb/train/neg/'):\n",
    "                    yield self._read(archive, filename), False\n",
    "                    \n",
    "    def _read(self, archive, filename):\n",
    "        with archive.extractfile(filename) as file_:\n",
    "            data = file_.read().decode('utf-8')\n",
    "            data = type(self).TOKEN_REGEX.findall(data)\n",
    "            data = [x.lower() for x in data]\n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Spacy is my favourite nlp framework, which havu builtin word embeddings trains on wikipesia\n",
    "from spacy.en import English\n",
    "\n",
    "class Embedding:\n",
    "    \n",
    "    def __init__(self):\n",
    "#          spaCy makes using word vectors very easy. \n",
    "#             The Lexeme , Token , Span  and Doc  classes all have a .vector property,\n",
    "#             which is a 1-dimensional numpy array of 32-bit floats:\n",
    "        self.parser = English()\n",
    "#         self._length = length\n",
    "        self.dimensions = 300\n",
    "        \n",
    "    def __call__(self, sequence, length):\n",
    "        # DO I really need them to be equal length?\n",
    "        # Let's assume I'm not\n",
    "        data = np.zeros((length, self.dimensions))\n",
    "        # you can access known words from the parser's vocabulary\n",
    "        embedded = [self.parser.vocab[w].vector for w in sequence]\n",
    "        data[:len(sequence)] = embedded\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def preprocess_batched_split(iterator, embedding, batch_size):\n",
    "    iterator = iter(iterator)\n",
    "    while True:\n",
    "        batch = []\n",
    "        labelss = []\n",
    "        sentence_sizes_batch = []\n",
    "        for index in range(batch_size):\n",
    "            text, label = next(iterator)\n",
    "            sents = [list(y) for x, y in itertools.groupby(text, lambda z: z == '.') if not x]\n",
    "            sentence_sizes = [len(s) for s in sents]\n",
    "            text_embed = [embedding(sent) for sent in sents]\n",
    "            \n",
    "            batch.append(text_embed)\n",
    "            labelss.append(label)\n",
    "            sentence_sizes_batch.append(sentence_sizes)\n",
    "            \n",
    "        labels_batch = np.array(labelss, dtype=np.int32)\n",
    "        sent_per_doc = np.array([len(x) for x in sentence_sizes_batch])\n",
    "        words_per_sent_per_doc = np.array(sentence_sizes_batch)\n",
    "        yield np.array(batch), labels_batch, words_per_sent_per_doc, sent_per_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def preprocess_batched_split2(iterator, embedding, batch_size):\n",
    "    iterator = iter(iterator)\n",
    "    while True:\n",
    "        batch, labels_b = zip(*itertools.islice(iterator, batch_size))\n",
    "        \n",
    "        sents_b = [[list(y) for x, y in itertools.groupby(doc, lambda z: z == '.') if not x] for doc in batch]\n",
    "\n",
    "        sentence_sizes_b = [[len(sent) for sent in doc] for doc in sents_b]\n",
    "        sentence_size = max(map(max, sentence_sizes_b))\n",
    "        \n",
    "        document_sizes = np.array([len(doc) for doc in sentence_sizes_b], dtype=np.int32)\n",
    "        document_size = document_sizes.max()\n",
    "\n",
    "        sentence_sizes_np = np.zeros(shape=[batch_size, document_size], dtype=np.int32)\n",
    "        for bi, ds, ss in zip(range(sentence_sizes_np.shape[0]), document_sizes, sentence_sizes_b):\n",
    "            sentence_sizes_np[bi][:ds] = ss\n",
    "        \n",
    "        text_embed_b = np.zeros((batch_size, document_size, sentence_size, 300))\n",
    "        for i, ds, doc_sents in zip(range(text_embed_b.shape[0]), document_sizes, sents_b):\n",
    "            doc_sents_embed = np.array([embedding(sent, sentence_size) for sent in doc_sents])\n",
    "            text_embed_b[i][:ds] = doc_sents_embed\n",
    "        \n",
    "        yield text_embed_b, np.array(labels_b, dtype=np.int32), np.array(document_sizes), sentence_sizes_np, sents_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = list(ImdbMovieReviews())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "HanSequenceLabellingModel model_components\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport HanSequenceLabellingModel, model_components\n",
    "%aimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_split = preprocess_batched_split2(reviews, Embedding(), batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HanSequenceLabellingModel import HanSequenceLabellingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HAN_model_1(session, restore_only=False):\n",
    "    \"\"\"Hierarhical Attention Network\"\"\"\n",
    "    import tensorflow as tf\n",
    "    try:\n",
    "        from tensorflow.contrib.rnn import GRUCell, MultiRNNCell, DropoutWrapper\n",
    "    except ImportError:\n",
    "        MultiRNNCell = tf.nn.rnn_cell.MultiRNNCell\n",
    "        GRUCell = tf.nn.rnn_cell.GRUCell\n",
    "    from bn_lstm import BNLSTMCell\n",
    "    from HanSequenceLabellingModel import HanSequenceLabellingModel\n",
    "\n",
    "    is_training = tf.placeholder(dtype=tf.bool, name='is_training')\n",
    "\n",
    "    cell = BNLSTMCell(80, is_training) # h-h batchnorm LSTMCell\n",
    "    cell = MultiRNNCell([cell]*5)\n",
    "\n",
    "    model = HanSequenceLabellingModel(\n",
    "            embedding_size=300,\n",
    "            classes=2,\n",
    "            word_cell=cell,\n",
    "            sentence_cell=cell,\n",
    "            word_output_size=300,\n",
    "            sentence_output_size=300,\n",
    "            learning_rate=0.001,\n",
    "            max_grad_norm=5.0,\n",
    "            dropout_keep_proba=0.5,\n",
    "            is_training=is_training,\n",
    "    )\n",
    "\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    checkpoint_dir = 'checkpoints'\n",
    "    checkpoint = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "    if checkpoint:\n",
    "        print(\"Reading model parameters from %s\" % checkpoint.model_checkpoint_path)\n",
    "        saver.restore(session, checkpoint.model_checkpoint_path)\n",
    "    elif restore_only:\n",
    "        raise FileNotFoundError(\"Cannot restore model\")\n",
    "    else:\n",
    "        print(\"Created model with fresh parameters\")\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        \n",
    "    return model, saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model parameters from checkpoints/checkpoint-2400\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/checkpoint-2400\n",
      "\u001b[30;48;2;255;125;125m   \u001b[0m \u001b[30;48;2;188;188;255mi\u001b[0m \u001b[30;48;2;213;213;255mhave\u001b[0m \u001b[30;48;2;224;224;255mto\u001b[0m \u001b[30;48;2;220;220;255madmit\u001b[0m \u001b[30;48;2;229;229;255mthat\u001b[0m \u001b[30;48;2;228;228;255mtsui\u001b[0m \u001b[30;48;2;228;228;255mhark\u001b[0m \u001b[30;48;2;222;222;255mis\u001b[0m \u001b[30;48;2;222;222;255mone\u001b[0m \u001b[30;48;2;220;220;255mof\u001b[0m \u001b[30;48;2;219;219;255ma\u001b[0m \u001b[30;48;2;220;220;255mkind\u001b[0m \u001b[30;48;2;218;218;255m,\u001b[0m \u001b[30;48;2;216;216;255myou\u001b[0m \u001b[30;48;2;215;215;255mcan\u001b[0m \u001b[30;48;2;214;214;255mt\u001b[0m \u001b[30;48;2;208;208;255mtop\u001b[0m \u001b[30;48;2;208;208;255ma\u001b[0m \u001b[30;48;2;211;211;255mperson\u001b[0m \u001b[30;48;2;207;207;255mwith\u001b[0m \u001b[30;48;2;197;197;255ma\u001b[0m \u001b[30;48;2;186;186;255mstrong\u001b[0m \u001b[30;48;2;182;182;255mstyle\u001b[0m \u001b[30;48;2;182;182;255mof\u001b[0m \u001b[30;48;2;155;155;255mmovie\u001b[0m \u001b[30;48;2;183;183;255mpresence\u001b[0m \n",
      "\u001b[30;48;2;255;106;106m   \u001b[0m \u001b[30;48;2;224;224;255ma\u001b[0m \u001b[30;48;2;229;229;255mchinese\u001b[0m \u001b[30;48;2;225;225;255mfantasy\u001b[0m \u001b[30;48;2;215;215;255mpicture\u001b[0m \u001b[30;48;2;223;223;255mmay\u001b[0m \u001b[30;48;2;229;229;255mnot\u001b[0m \u001b[30;48;2;238;238;255mbe\u001b[0m \u001b[30;48;2;239;239;255measy\u001b[0m \u001b[30;48;2;241;241;255mto\u001b[0m \u001b[30;48;2;241;241;255mpresent\u001b[0m \u001b[30;48;2;240;240;255mto\u001b[0m \u001b[30;48;2;241;241;255man\u001b[0m \u001b[30;48;2;239;239;255maudience\u001b[0m \u001b[30;48;2;231;231;255m,\u001b[0m \u001b[30;48;2;222;222;255mthe\u001b[0m \u001b[30;48;2;206;206;255mdirector\u001b[0m \u001b[30;48;2;180;180;255mattempted\u001b[0m \u001b[30;48;2;215;215;255mto\u001b[0m \u001b[30;48;2;225;225;255mbring\u001b[0m \u001b[30;48;2;226;226;255mback\u001b[0m \u001b[30;48;2;223;223;255mthe\u001b[0m \u001b[30;48;2;206;206;255mclassic\u001b[0m \u001b[30;48;2;194;194;255mfantasy\u001b[0m \u001b[30;48;2;190;190;255mtales\u001b[0m \u001b[30;48;2;194;194;255mof\u001b[0m \u001b[30;48;2;203;203;255mzu\u001b[0m \u001b[30;48;2;198;198;255mmountain\u001b[0m \u001b[30;48;2;199;199;255mand\u001b[0m \u001b[30;48;2;182;182;255mthis\u001b[0m \u001b[30;48;2;165;165;255mis\u001b[0m \u001b[30;48;2;166;166;255mwhat\u001b[0m \u001b[30;48;2;175;175;255mhe\u001b[0m \u001b[30;48;2;155;155;255mdisplayed\u001b[0m \n",
      "\u001b[30;48;2;255;148;148m   \u001b[0m \u001b[30;48;2;205;205;255mbr\u001b[0m \u001b[30;48;2;211;211;255mbr\u001b[0m \u001b[30;48;2;206;206;255mthe\u001b[0m \u001b[30;48;2;205;205;255mnew\u001b[0m \u001b[30;48;2;189;189;255mlegend\u001b[0m \u001b[30;48;2;190;190;255mof\u001b[0m \u001b[30;48;2;190;190;255mzu\u001b[0m \u001b[30;48;2;187;187;255mhas\u001b[0m \u001b[30;48;2;155;155;255mtruly\u001b[0m \u001b[30;48;2;164;164;255mimproved\u001b[0m \u001b[30;48;2;198;198;255mfrom\u001b[0m \u001b[30;48;2;201;201;255mthe\u001b[0m \u001b[30;48;2;200;200;255mone\u001b[0m \u001b[30;48;2;209;209;255min\u001b[0m \n",
      "\u001b[30;48;2;255;185;185m   \u001b[0m \u001b[30;48;2;173;173;255mfrom\u001b[0m \u001b[30;48;2;155;155;255mthis\u001b[0m \u001b[30;48;2;180;180;255mnew\u001b[0m \u001b[30;48;2;189;189;255mmillenium\u001b[0m \u001b[30;48;2;197;197;255mupdate\u001b[0m \u001b[30;48;2;189;189;255m,\u001b[0m \u001b[30;48;2;194;194;255mwe\u001b[0m \u001b[30;48;2;204;204;255mcould\u001b[0m \u001b[30;48;2;215;215;255msee\u001b[0m \u001b[30;48;2;215;215;255mtsui\u001b[0m \u001b[30;48;2;213;213;255mhark\u001b[0m \u001b[30;48;2;211;211;255ms\u001b[0m \u001b[30;48;2;198;198;255mvision\u001b[0m \u001b[30;48;2;192;192;255mof\u001b[0m \u001b[30;48;2;186;186;255mthe\u001b[0m \u001b[30;48;2;186;186;255mzu\u001b[0m \u001b[30;48;2;158;158;255mmountains\u001b[0m \n",
      "\u001b[30;48;2;255;191;191m   \u001b[0m \u001b[30;48;2;155;155;255mspectacular\u001b[0m \u001b[30;48;2;178;178;255mvisual\u001b[0m \u001b[30;48;2;197;197;255mdesigns\u001b[0m \u001b[30;48;2;202;202;255m,\u001b[0m \u001b[30;48;2;202;202;255mamazing\u001b[0m \u001b[30;48;2;221;221;255maction\u001b[0m \u001b[30;48;2;226;226;255mfantasy\u001b[0m \u001b[30;48;2;230;230;255mepic\u001b[0m \u001b[30;48;2;236;236;255mmade\u001b[0m \u001b[30;48;2;240;240;255mbeautifully\u001b[0m \u001b[30;48;2;239;239;255mwell\u001b[0m \n",
      "\u001b[30;48;2;255;182;182m   \u001b[0m \u001b[30;48;2;172;172;255mkept\u001b[0m \u001b[30;48;2;196;196;255mme\u001b[0m \u001b[30;48;2;199;199;255mglued\u001b[0m \u001b[30;48;2;197;197;255mthrough\u001b[0m \u001b[30;48;2;180;180;255mthe\u001b[0m \u001b[30;48;2;162;162;255mentire\u001b[0m \u001b[30;48;2;155;155;255mpicture\u001b[0m \n",
      "\u001b[30;48;2;255;169;169m   \u001b[0m \u001b[30;48;2;155;155;255mgreat\u001b[0m \u001b[30;48;2;176;176;255mcast\u001b[0m \u001b[30;48;2;203;203;255mwith\u001b[0m \u001b[30;48;2;204;204;255mjust\u001b[0m \u001b[30;48;2;210;210;255mfine\u001b[0m \u001b[30;48;2;198;198;255macting\u001b[0m \n",
      "\u001b[30;48;2;255;83;83m   \u001b[0m \u001b[30;48;2;155;155;255mit\u001b[0m \u001b[30;48;2;195;195;255ms\u001b[0m \u001b[30;48;2;182;182;255mtruly\u001b[0m \u001b[30;48;2;211;211;255ma\u001b[0m \u001b[30;48;2;219;219;255mfun\u001b[0m \u001b[30;48;2;227;227;255mmovie\u001b[0m \u001b[30;48;2;237;237;255mto\u001b[0m \u001b[30;48;2;238;238;255mwatch\u001b[0m \u001b[30;48;2;238;238;255m,\u001b[0m \u001b[30;48;2;237;237;255mbut\u001b[0m \u001b[30;48;2;230;230;255mis\u001b[0m \u001b[30;48;2;210;210;255mit\u001b[0m \u001b[30;48;2;209;209;255mtoo\u001b[0m \u001b[30;48;2;209;209;255mweird\u001b[0m \u001b[30;48;2;213;213;255m?\u001b[0m \u001b[30;48;2;236;236;255mbr\u001b[0m \u001b[30;48;2;240;240;255mbr\u001b[0m \u001b[30;48;2;244;244;255mnow\u001b[0m \u001b[30;48;2;245;245;255mthe\u001b[0m \u001b[30;48;2;246;246;255mdown\u001b[0m \u001b[30;48;2;246;246;255mside\u001b[0m \u001b[30;48;2;244;244;255mis\u001b[0m \u001b[30;48;2;245;245;255mpeople\u001b[0m \u001b[30;48;2;246;246;255mwill\u001b[0m \u001b[30;48;2;242;242;255mdefinitely\u001b[0m \u001b[30;48;2;242;242;255mget\u001b[0m \u001b[30;48;2;239;239;255mconfused\u001b[0m \u001b[30;48;2;247;247;255mwith\u001b[0m \u001b[30;48;2;244;244;255mit\u001b[0m \u001b[30;48;2;245;245;255ms\u001b[0m \u001b[30;48;2;243;243;255mbroad\u001b[0m \u001b[30;48;2;233;233;255mstory\u001b[0m \u001b[30;48;2;221;221;255mline\u001b[0m \u001b[30;48;2;230;230;255mshortened\u001b[0m \u001b[30;48;2;236;236;255mdown\u001b[0m \u001b[30;48;2;241;241;255minto\u001b[0m \u001b[30;48;2;243;243;255ma\u001b[0m \u001b[30;48;2;236;236;255mminute\u001b[0m \u001b[30;48;2;230;230;255mmovie\u001b[0m \n",
      "\u001b[30;48;2;255;0;0m   \u001b[0m \u001b[30;48;2;155;155;255mplot\u001b[0m \u001b[30;48;2;211;211;255mmay\u001b[0m \u001b[30;48;2;225;225;255mnot\u001b[0m \u001b[30;48;2;241;241;255mhave\u001b[0m \u001b[30;48;2;245;245;255mmuch\u001b[0m \u001b[30;48;2;246;246;255mrelation\u001b[0m \u001b[30;48;2;246;246;255mamong\u001b[0m \u001b[30;48;2;242;242;255mcharacters\u001b[0m \u001b[30;48;2;240;240;255m,\u001b[0m \u001b[30;48;2;239;239;255mbut\u001b[0m \u001b[30;48;2;240;240;255mby\u001b[0m \u001b[30;48;2;241;241;255mrewatching\u001b[0m \u001b[30;48;2;242;242;255mthe\u001b[0m \u001b[30;48;2;234;234;255mmovie\u001b[0m \u001b[30;48;2;233;233;255m,\u001b[0m \u001b[30;48;2;232;232;255myou\u001b[0m \u001b[30;48;2;233;233;255mll\u001b[0m \u001b[30;48;2;240;240;255mhave\u001b[0m \u001b[30;48;2;243;243;255ma\u001b[0m \u001b[30;48;2;244;244;255mbetter\u001b[0m \u001b[30;48;2;240;240;255msense\u001b[0m \u001b[30;48;2;239;239;255mof\u001b[0m \u001b[30;48;2;234;234;255munderstanding\u001b[0m \u001b[30;48;2;232;232;255mthe\u001b[0m \u001b[30;48;2;218;218;255mcharacters\u001b[0m \u001b[30;48;2;204;204;255mitself\u001b[0m \n",
      "\u001b[30;48;2;255;62;62m   \u001b[0m \u001b[30;48;2;176;176;255msome\u001b[0m \u001b[30;48;2;182;182;255mcan\u001b[0m \u001b[30;48;2;155;155;255mcomplain\u001b[0m \u001b[30;48;2;199;199;255mthere\u001b[0m \u001b[30;48;2;204;204;255misn\u001b[0m \u001b[30;48;2;210;210;255mt\u001b[0m \u001b[30;48;2;215;215;255mtoo\u001b[0m \u001b[30;48;2;222;222;255mmuch\u001b[0m \u001b[30;48;2;223;223;255mphysical\u001b[0m \u001b[30;48;2;218;218;255mcombat\u001b[0m \u001b[30;48;2;201;201;255m,\u001b[0m \u001b[30;48;2;172;172;255mbesides\u001b[0m \u001b[30;48;2;209;209;255mwith\u001b[0m \u001b[30;48;2;189;189;255mcharacters\u001b[0m \u001b[30;48;2;192;192;255mthat\u001b[0m \u001b[30;48;2;205;205;255mhave\u001b[0m \u001b[30;48;2;210;210;255msupernatural\u001b[0m \u001b[30;48;2;211;211;255mpowers\u001b[0m \u001b[30;48;2;217;217;255mto\u001b[0m \u001b[30;48;2;218;218;255mdefeat\u001b[0m \u001b[30;48;2;221;221;255mfoes\u001b[0m \u001b[30;48;2;216;216;255m,\u001b[0m \u001b[30;48;2;215;215;255mspirits\u001b[0m \u001b[30;48;2;212;212;255mfighting\u001b[0m \u001b[30;48;2;210;210;255mby\u001b[0m \u001b[30;48;2;209;209;255mhand\u001b[0m \u001b[30;48;2;211;211;255mto\u001b[0m \u001b[30;48;2;209;209;255mhand\u001b[0m \u001b[30;48;2;208;208;255mwouldn\u001b[0m \u001b[30;48;2;213;213;255mt\u001b[0m \u001b[30;48;2;223;223;255mreally\u001b[0m \u001b[30;48;2;222;222;255mmake\u001b[0m \u001b[30;48;2;219;219;255msense\u001b[0m \u001b[30;48;2;217;217;255mat\u001b[0m \u001b[30;48;2;215;215;255mall\u001b[0m \n",
      "\u001b[30;48;2;255;82;82m   \u001b[0m \u001b[30;48;2;192;192;255mbr\u001b[0m \u001b[30;48;2;191;191;255mbr\u001b[0m \u001b[30;48;2;169;169;255mi\u001b[0m \u001b[30;48;2;155;155;255mappreciated\u001b[0m \u001b[30;48;2;170;170;255mthis\u001b[0m \u001b[30;48;2;163;163;255mnice\u001b[0m \u001b[30;48;2;180;180;255mstylish\u001b[0m \u001b[30;48;2;184;184;255mpicture\u001b[0m \n",
      "\u001b[30;48;2;255;15;15m   \u001b[0m \u001b[30;48;2;213;213;255mit\u001b[0m \u001b[30;48;2;231;231;255mmay\u001b[0m \u001b[30;48;2;237;237;255mhave\u001b[0m \u001b[30;48;2;240;240;255ma\u001b[0m \u001b[30;48;2;227;227;255mthin\u001b[0m \u001b[30;48;2;237;237;255mstory\u001b[0m \u001b[30;48;2;233;233;255m,\u001b[0m \u001b[30;48;2;230;230;255mbut\u001b[0m \u001b[30;48;2;231;231;255mhey\u001b[0m \u001b[30;48;2;235;235;255mlook\u001b[0m \u001b[30;48;2;240;240;255mat\u001b[0m \u001b[30;48;2;243;243;255mtsui\u001b[0m \u001b[30;48;2;245;245;255mhark\u001b[0m \u001b[30;48;2;247;247;255ms\u001b[0m \u001b[30;48;2;246;246;255mtime\u001b[0m \u001b[30;48;2;244;244;255mtide\u001b[0m \u001b[30;48;2;239;239;255m,\u001b[0m \u001b[30;48;2;237;237;255mwe\u001b[0m \u001b[30;48;2;238;238;255mgot\u001b[0m \u001b[30;48;2;234;234;255mconfused\u001b[0m \u001b[30;48;2;239;239;255mby\u001b[0m \u001b[30;48;2;236;236;255mthe\u001b[0m \u001b[30;48;2;210;210;255mplot\u001b[0m \u001b[30;48;2;205;205;255mas\u001b[0m \u001b[30;48;2;198;198;255mwell\u001b[0m \u001b[30;48;2;197;197;255m,\u001b[0m \u001b[30;48;2;192;192;255mbut\u001b[0m \u001b[30;48;2;175;175;255mit\u001b[0m \u001b[30;48;2;185;185;255mwas\u001b[0m \u001b[30;48;2;155;155;255mtruly\u001b[0m \u001b[30;48;2;174;174;255msomething\u001b[0m \u001b[30;48;2;181;181;255mstylish\u001b[0m \u001b[30;48;2;177;177;255mand\u001b[0m \u001b[30;48;2;172;172;255mawesome\u001b[0m \n",
      "\u001b[30;48;2;255;49;49m   \u001b[0m \u001b[30;48;2;155;155;255mtsui\u001b[0m \u001b[30;48;2;175;175;255mhark\u001b[0m \u001b[30;48;2;181;181;255malways\u001b[0m \u001b[30;48;2;177;177;255mattracts\u001b[0m \u001b[30;48;2;173;173;255msomething\u001b[0m \u001b[30;48;2;181;181;255mdifferent\u001b[0m \u001b[30;48;2;179;179;255minto\u001b[0m \u001b[30;48;2;173;173;255mh\u001b[0m \n",
      "\u001b[30;48;2;255;127;127m   \u001b[0m \u001b[30;48;2;155;155;255mk\u001b[0m \n",
      "\u001b[30;48;2;255;148;148m   \u001b[0m \u001b[30;48;2;155;155;255mcinema\u001b[0m \n",
      "\u001b[30;48;2;255;114;114m   \u001b[0m \u001b[30;48;2;226;226;255mamerican\u001b[0m \u001b[30;48;2;227;227;255maudiences\u001b[0m \u001b[30;48;2;219;219;255m,\u001b[0m \u001b[30;48;2;220;220;255mmay\u001b[0m \u001b[30;48;2;226;226;255mhave\u001b[0m \u001b[30;48;2;233;233;255msome\u001b[0m \u001b[30;48;2;237;237;255mdifficulty\u001b[0m \u001b[30;48;2;239;239;255mto\u001b[0m \u001b[30;48;2;239;239;255munderstand\u001b[0m \u001b[30;48;2;236;236;255mwhile\u001b[0m \u001b[30;48;2;232;232;255mwatching\u001b[0m \u001b[30;48;2;219;219;255mthis\u001b[0m \u001b[30;48;2;183;183;255mmovie\u001b[0m \u001b[30;48;2;155;155;255m,\u001b[0m \u001b[30;48;2;159;159;255mcause\u001b[0m \u001b[30;48;2;164;164;255mthis\u001b[0m \u001b[30;48;2;160;160;255main\u001b[0m \u001b[30;48;2;181;181;255mt\u001b[0m \u001b[30;48;2;194;194;255mno\u001b[0m \u001b[30;48;2;223;223;255mcrouching\u001b[0m \u001b[30;48;2;223;223;255mtiger\u001b[0m \u001b[30;48;2;216;216;255m,\u001b[0m \u001b[30;48;2;209;209;255mhidden\u001b[0m \u001b[30;48;2;209;209;255mdragon\u001b[0m \u001b[30;48;2;202;202;255m,\u001b[0m \u001b[30;48;2;183;183;255mthis\u001b[0m \u001b[30;48;2;163;163;255mis\u001b[0m \u001b[30;48;2;158;158;255ma\u001b[0m \u001b[30;48;2;162;162;255mwhole\u001b[0m \u001b[30;48;2;186;186;255mnew\u001b[0m \u001b[30;48;2;170;170;255mgenre\u001b[0m \n",
      "\u001b[30;48;2;255;133;133m   \u001b[0m \u001b[30;48;2;230;230;255malthough\u001b[0m \u001b[30;48;2;213;213;255mit\u001b[0m \u001b[30;48;2;220;220;255mmay\u001b[0m \u001b[30;48;2;224;224;255mnot\u001b[0m \u001b[30;48;2;232;232;255mbe\u001b[0m \u001b[30;48;2;231;231;255ma\u001b[0m \u001b[30;48;2;228;228;255mmasterpiece\u001b[0m \u001b[30;48;2;218;218;255m,\u001b[0m \u001b[30;48;2;209;209;255mbut\u001b[0m \u001b[30;48;2;190;190;255mit\u001b[0m \u001b[30;48;2;200;200;255ms\u001b[0m \u001b[30;48;2;205;205;255mspecial\u001b[0m \u001b[30;48;2;202;202;255meffects\u001b[0m \u001b[30;48;2;184;184;255mis\u001b[0m \u001b[30;48;2;164;164;255mtruly\u001b[0m \u001b[30;48;2;155;155;255mbetter\u001b[0m \u001b[30;48;2;199;199;255mthan\u001b[0m \u001b[30;48;2;223;223;255mstorm\u001b[0m \u001b[30;48;2;227;227;255mriders\u001b[0m \n",
      "\u001b[30;48;2;255;100;100m   \u001b[0m \u001b[30;48;2;155;155;255mthis\u001b[0m \u001b[30;48;2;169;169;255mis\u001b[0m \u001b[30;48;2;184;184;255mreally\u001b[0m \u001b[30;48;2;196;196;255mworth\u001b[0m \u001b[30;48;2;216;216;255mchecking\u001b[0m \u001b[30;48;2;227;227;255mout\u001b[0m \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from colors import color\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "\n",
    "with tf.Session(config=config) as s:\n",
    "    model, saver = HAN_model_1(s)\n",
    "\n",
    "    for data, labels_batch, sent_per_doc, words_per_sent_per_doc, sents_b in batches_split:\n",
    "\n",
    "        fd = {\n",
    "            model.is_training: True,\n",
    "            model.inputs_embedded: data,\n",
    "            model.word_lengths: words_per_sent_per_doc,\n",
    "            model.sentence_lengths: sent_per_doc,\n",
    "            model.labels: labels_batch,\n",
    "            model.sample_weights: np.ones(shape=(10))\n",
    "        }\n",
    "\n",
    "        word_attention, sentence_attention = s.run([model.word_attention, model.sentence_attention], feed_dict=fd)\n",
    "        max_len = sentence_attention.shape[1]\n",
    "        \n",
    "        for i, review in enumerate(sents_b):\n",
    "            for j, sentence in enumerate(review): \n",
    "                capacity = 255 - int(255 * sentence_attention[i, j, 0] / np.max(sentence_attention[i]))\n",
    "                print(color('   ', 'black', '#ff{cap:02x}{cap:02x}'.format(cap=capacity)), end=' ')\n",
    "                for k, word in enumerate(sentence):\n",
    "                    capacity = 255 - int(100 * word_attention[i * max_len + j, k, 0] / \\\n",
    "                                         np.max(word_attention[i * max_len + j]))\n",
    "                    print(color(word, 'black', '#{cap:02x}{cap:02x}ff'.format(cap=capacity)), end=' ')\n",
    "                print()\n",
    "            print()\n",
    "            break\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_split = preprocess_batched_split2(reviews, Embedding(), batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model parameters from checkpoints/checkpoint-2400\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/checkpoint-2400\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "\n",
    "#           label:  '0', '1'\n",
    "attention_values = [[[], []], # 'good'\n",
    "                    [[], []]] # 'bad'\n",
    "\n",
    "word_ind = lambda word: 0 if word == 'good' else 1 if word == 'bad' else False\n",
    "\n",
    "with tf.Session(config=config) as s:\n",
    "    model, saver = HAN_model_1(s)\n",
    "\n",
    "    for t, (data, labels_batch, sent_per_doc, words_per_sent_per_doc, sents_b) in enumerate(batches_split):\n",
    "        \n",
    "        if t > 2000:\n",
    "            break\n",
    "        \n",
    "        if t % 200 == 0:\n",
    "            print(t)\n",
    "\n",
    "        fd = {\n",
    "            model.is_training: True,\n",
    "            model.inputs_embedded: data,\n",
    "            model.word_lengths: words_per_sent_per_doc,\n",
    "            model.sentence_lengths: sent_per_doc,\n",
    "            model.labels: labels_batch,\n",
    "            model.sample_weights: np.ones(shape=(10))\n",
    "        }\n",
    "\n",
    "        word_attention = s.run(model.word_attention, feed_dict=fd)\n",
    "        max_len = int(word_attention.shape[0] / len(sents_b))\n",
    "        \n",
    "        for i, review in enumerate(sents_b):\n",
    "            for j, sentence in enumerate(review): \n",
    "                for k, word in enumerate(sentence):\n",
    "                    x = word_ind(word)\n",
    "                    if type(x) == int:\n",
    "                        attention_values[x][int(labels_batch[i])].append(word_attention[i * max_len + j, k, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
